<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Training a LSTM · ml5js</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="&lt;p&gt;This short tutorial will go over how to train a custom LSTM on your own dataset and then use the results in ml5.js &lt;a href=&quot;/docs/LSTMGenerator&quot;&gt;LSTMGenerator()&lt;/a&gt; method. For this, you will need a dataset of text you would like to use. Take a look at some of the ones we are using &lt;a href=&quot;https://github.com/ml5js/ml5-data-and-models/tree/master/datasets/text&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Training a LSTM · ml5js"/><meta property="og:type" content="website"/><meta property="og:url" content="ml5js.org/index.html"/><meta property="og:description" content="&lt;p&gt;This short tutorial will go over how to train a custom LSTM on your own dataset and then use the results in ml5.js &lt;a href=&quot;/docs/LSTMGenerator&quot;&gt;LSTMGenerator()&lt;/a&gt; method. For this, you will need a dataset of text you would like to use. Take a look at some of the ones we are using &lt;a href=&quot;https://github.com/ml5js/ml5-data-and-models/tree/master/datasets/text&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
"/><meta property="og:image" content="ml5js.org/img/og.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="ml5js.org/img/og.png"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"/><script type="text/javascript" src="/scripts/p5.min.js"></script><script type="text/javascript" src="/scripts/p5.dom.min.js"></script><script type="text/javascript" src="/scripts/p5.sound.min.js"></script><script type="text/javascript" src="/scripts/ml5.min.js"></script><link rel="stylesheet" href="/css/main.css"/></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/ml5.png" alt="ml5js"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/getting-started" target="_self">Reference</a></li><li class="siteNavGroupActive"><a href="/docs/quick-start" target="_self">Examples</a></li><li class="siteNavGroupActive"><a href="/docs/data-overview" target="_self">Data</a></li><li class="siteNavGroupActive"><a href="/docs/training-introduction" target="_self">Training</a></li><li class=""><a href="/experiments" target="_self">Experiments</a></li><li class=""><a href="/docs/glossary-machine-learning" target="_self">Learn</a></li><li class=""><a href="https://github.com/ml5js" target="_self">Code</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>Training</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Documentation</h3><ul><li class="navListItem"><a class="navItem" href="/docs/getting-started">Getting Started</a></li><li class="navListItem"><a class="navItem" href="/docs/promises-callback">Promises and Callbacks</a></li><li class="navListItem"><a class="navItem" href="/docs/CharRNN">charRNN()</a></li><li class="navListItem"><a class="navItem" href="/docs/FeatureExtractor">featureExtractor()</a></li><li class="navListItem"><a class="navItem" href="/docs/ImageClassifier">imageClassifier()</a></li><li class="navListItem"><a class="navItem" href="/docs/KNNClassifier">KNNClassifier()</a></li><li class="navListItem"><a class="navItem" href="/docs/PitchDetection">pitchDetection()</a></li><li class="navListItem"><a class="navItem" href="/docs/Pix2Pix">pix2pix()</a></li><li class="navListItem"><a class="navItem" href="/docs/PoseNet">poseNet()</a></li><li class="navListItem"><a class="navItem" href="/docs/SketchRNN">SketchRNN()</a></li><li class="navListItem"><a class="navItem" href="/docs/StyleTransfer">styleTransfer()</a></li><li class="navListItem"><a class="navItem" href="/docs/Word2vec">word2vec()</a></li><li class="navListItem"><a class="navItem" href="/docs/YOLO">YOLO()</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Examples</h3><ul><li class="navListItem"><a class="navItem" href="/docs/quick-start">Quick Start</a></li><li class="navListItem"><a class="navItem" href="/docs/image-classification-example">Image Classification</a></li><li class="navListItem"><a class="navItem" href="/docs/video-classification-example">Video Classification</a></li><li class="navListItem"><a class="navItem" href="/docs/custom-classifier">Classifier with Feature Extractor</a></li><li class="navListItem"><a class="navItem" href="/docs/custom-regression">Regression with Feature Extractor</a></li><li class="navListItem"><a class="navItem" href="/docs/knnclassifier">KNN Classifier with Feature Extractor</a></li><li class="navListItem"><a class="navItem" href="/docs/knnclassifier-posenet">KNN Classifier with PoseNet</a></li><li class="navListItem"><a class="navItem" href="/docs/lstm-example">Text Generation with LSTM</a></li><li class="navListItem"><a class="navItem" href="/docs/lstm-interactive-example">Interactive Text Generation LSTM</a></li><li class="navListItem"><a class="navItem" href="/docs/sketchrnn-example">SketchRNN</a></li><li class="navListItem"><a class="navItem" href="/docs/style-transfer-image-example">Style Transfer</a></li><li class="navListItem"><a class="navItem" href="/docs/style-transfer-webcam-example">Style Transfer with Webcam</a></li><li class="navListItem"><a class="navItem" href="/docs/pix2pix-example">Pix2Pix</a></li><li class="navListItem"><a class="navItem" href="/docs/posenet-webcam">PoseNet with Webcam</a></li><li class="navListItem"><a class="navItem" href="/docs/yolo-webcam">YOLO with Webcam</a></li><li class="navListItem"><a class="navItem" href="/docs/word2vec-example">Word2Vec</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Data</h3><ul><li class="navListItem"><a class="navItem" href="/docs/data-overview">Overview</a></li><li class="navListItem"><a class="navItem" href="/docs/data-collection">Data Collection</a></li><li class="navListItem"><a class="navItem" href="/docs/data-types-of-datasets">Types of Data</a></li><li class="navListItem"><a class="navItem" href="/docs/data-preparing-your-own-data">Preparing your own data</a></li><li class="navListItem"><a class="navItem" href="/docs/data-creating-your-own-data">Creating your data</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Training</h3><ul><li class="navListItem"><a class="navItem" href="/docs/training-introduction">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/training-setup">Setting up</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/training-lstm">Training a LSTM</a></li><li class="navListItem"><a class="navItem" href="/docs/training-styletransfer">Training Style Transfer</a></li><li class="navListItem"><a class="navItem" href="/docs/training-pix2pix">Training Pix2Pix</a></li></ul></div></div></section></div><script>
            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              const headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                if (event.target.tagName === 'A') {
                  document.body.classList.remove('tocActive');
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Training a LSTM</h1></header><article><div><span><p>This short tutorial will go over how to train a custom LSTM on your own dataset and then use the results in ml5.js <a href="/docs/LSTMGenerator">LSTMGenerator()</a> method. For this, you will need a dataset of text you would like to use. Take a look at some of the ones we are using <a href="https://github.com/ml5js/ml5-data-and-models/tree/master/datasets/text">here</a>.</p>
<p>The code for this tutorial is based on <a href="https://github.com/sherjilozair/char-rnn-tensorflow">Sherjil Ozair</a> version of <a href="https://karpathy.github.io/">Andrej Karpathy's</a> <a href="https://github.com/karpathy/char-rnn">char-rnn code</a>.</p>
<p><strong>This are the same instructions you can find in <a href="https://github.com/ml5js/training-lstm">this repository</a></strong></p>
<h2><a class="anchor" aria-hidden="true" id="requirements"></a><a href="#requirements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Requirements</h2>
<ul>
<li><p>Set up a python environment with tensorflow installed. <a href="../">More detailed instructions here</a></p></li>
<li><p>If you are familiar with Docker, you can also use this  <del><a href="">container</a></del> (soon!)</p></li>
<li><p>You can also train your model in <a href="https://www.paperspace.com/">Paperspace</a>, using <a href="https://blog.paperspace.com/training-an-lstm-and-using-the-model-in-ml5-js/">this tutorial</a>.</p></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="usage"></a><a href="#usage" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<h3><a class="anchor" aria-hidden="true" id="1-download-the-repository"></a><a href="#1-download-the-repository" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1) Download the repository</h3>
<p>Start by <a href="https://github.com/ml5js/training-lstm">downloading</a> or cloning the training repository:</p>
<pre><code class="hljs css language-bash">git <span class="hljs-built_in">clone</span> https://github.com/ml5js/training-lstm.git
<span class="hljs-built_in">cd</span> training-lstm
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="2-collect-data"></a><a href="#2-collect-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2) Collect data</h3>
<p>LSTMs work well when you want predict sequences or patterns from your inputs. Try to gather as much input data as you can. The more the better.</p>
<p>Once your data is ready, create a new folder in the <code>root</code> of this project and inside that folder you should have one file called <code>input.txt</code> that contains all your training data.</p>
<p><em>(A quick tip to concatenate many small disparate <code>.txt</code> files into one large training file: <code>ls *.txt | xargs -L 1 cat &gt;&gt; input.txt</code>)</em></p>
<h3><a class="anchor" aria-hidden="true" id="2-train"></a><a href="#2-train" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2) Train</h3>
<p>Run the training script with the default settings:</p>
<pre><code class="hljs css language-bash">python train.py --data_dir=./folder_with_my_custom_data
</code></pre>
<p>Or you can specify the hyperparameters you want depending on the training set, size of your data, etc:</p>
<pre><code class="hljs css language-bash">python train.py --data_dir=./folder_with_my_custom_data --rnn_size 128 --num_layers 2 --seq_length 64 --batch_size 32 --num_epochs 1000 --save_model ./models --save_checkpoints ./checkpoints
</code></pre>
<p>This will train your model and save a JavaScript version <strong>in a folder called <code>./models</code></strong>, if you don't specify a different path.</p>
<p>You can also run the script called <code>run.sh</code>:</p>
<pre><code class="hljs css language-bash">bash run.sh
</code></pre>
<p>This file contains the same parameters as the one's described before:</p>
<pre><code class="hljs css language-bash"><span class="hljs-comment"># This are the hyperparameters you can change to fit your data</span>
python train.py --data_dir=./bronte \
--rnn_size 128 \
--num_layers 2 \
--seq_length 50 \
--batch_size 50 \
--num_epochs 50 \
--save_checkpoints ./checkpoints \
--save_model ./models
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="3-use-it"></a><a href="#3-use-it" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3) Use it!</h3>
<p>Once the model is ready, you'll just need to point to it in your ml5 sketch:</p>
<pre><code class="hljs css language-javascript"><span class="hljs-keyword">const</span> lstm = <span class="hljs-keyword">new</span> ml5.LSTMGenerator(<span class="hljs-string">'./models/your_new_model'</span>);
</code></pre>
<p>That's it!</p>
<h2><a class="anchor" aria-hidden="true" id="hyperparameters"></a><a href="#hyperparameters" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hyperparameters</h2>
<p>Given the size of the training dataset, here are some hyperparameters that might work:</p>
<ul>
<li>2 MB:
<ul>
<li>rnn_size 256 (or 128)</li>
<li>layers 2</li>
<li>seq_length 64</li>
<li>batch_size 32</li>
<li>dropout 0.25</li>
</ul></li>
<li>5-8 MB:
<ul>
<li>rnn_size 512</li>
<li>layers 2 (or 3)</li>
<li>seq_length 128</li>
<li>batch_size 64</li>
<li>dropout 0.25</li>
</ul></li>
<li>10-20 MB:
<ul>
<li>rnn_size 1024</li>
<li>layers 2 (or 3)</li>
<li>seq_length 128 (or 256)</li>
<li>batch_size 128</li>
<li>dropout 0.25</li>
</ul></li>
<li>25+ MB:
<ul>
<li>rnn_size 2048</li>
<li>layers 2 (or 3)</li>
<li>seq_length 256 (or 128)</li>
<li>batch_size 128</li>
<li>dropout 0.25</li>
</ul></li>
</ul>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/training-setup"><span class="arrow-prev">← </span><span>Setting up</span></a><a class="docs-next button" href="/docs/training-styletransfer"><span>Training Style Transfer</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#requirements">Requirements</a></li><li><a href="#usage">Usage</a><ul class="toc-headings"><li><a href="#1-download-the-repository">1) Download the repository</a></li><li><a href="#2-collect-data">2) Collect data</a></li><li><a href="#2-train">2) Train</a></li><li><a href="#3-use-it">3) Use it!</a></li></ul></li><li><a href="#hyperparameters">Hyperparameters</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><div><h5>Docs</h5><a href="/docs/getting-started.html">Getting Started</a><a href="/docs/ImageClassifier.html">API Reference</a><a href="/docs/training-setup.html">Training Models</a></div><div><h5>Learning</h5><a href="/docs/tutorials.html">Tutorials</a><a href="/docs/glossary-machine-learning.html">Glossary</a><a href="/docs/resources.html">Resources</a></div><div><h5>Contribute</h5><a href="/experiments.html">Experiments</a><a href="https://github.com/ml5js/ml5-library/blob/master/CONTRIBUTING.md">Contributing</a><a class="github-button" href="https://github.com/ml5js/ml5-library" data-icon="octicon-star" data-count-href="https://github.com/ml5js/ml5-library" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://itp.nyu.edu" target="_blank" class="fbOpenSource"><img src="/img/itp_logo.png" alt="Facebook Open Source" width="60" height="45"/></a><section class="copyright">This project is currently being maintained at NYU ITP by a community of teachers, residents and students.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>window.twttr=(function(d,s, id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return t;js=d.createElement(s);js.id=id;js.src='https://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js, fjs);t._e = [];t.ready = function(f) {t._e.push(f);};return t;}(document, 'script', 'twitter-wjs'));</script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '4e9582fa59998b865a9fd98ae8d8a9cc',
                indexName: 'ml5js',
                inputSelector: '#search_input_react'
              });
            </script></body></html>